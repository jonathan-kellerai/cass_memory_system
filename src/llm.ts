// src/llm.ts
// LLM Provider Abstraction - Using Vercel AI SDK
// Supports OpenAI, Anthropic, and Google providers with a unified interface

import { createOpenAI } from "@ai-sdk/openai";
import { createAnthropic } from "@ai-sdk/anthropic";
import { createGoogleGenerativeAI } from "@ai-sdk/google";
import { generateObject, type LanguageModel } from "ai";
import { z } from "zod";
import type { Config, DiaryEntry } from "./types";

/**
 * Supported LLM provider names
 */
export type LLMProvider = "openai" | "anthropic" | "google";

/**
 * Minimal config interface for LLM operations.
 */
export interface LLMConfig {
  provider: LLMProvider;
  model: string;
  apiKey?: string;
}

/**
 * Map of provider names to environment variable names
 */
const ENV_VAR_MAP: Record<LLMProvider, string> = {
  openai: "OPENAI_API_KEY",
  anthropic: "ANTHROPIC_API_KEY",
  google: "GOOGLE_GENERATIVE_AI_API_KEY",
};

/**
 * Expected key prefixes for format validation
 */
const KEY_PREFIX_MAP: Record<LLMProvider, string> = {
  openai: "sk-",
  anthropic: "sk-ant-",
  google: "AIza",
};

export function getApiKey(provider: string): string {
  const normalized = provider.trim().toLowerCase() as LLMProvider;

  const envVar = ENV_VAR_MAP[normalized];
  if (!envVar) {
    const supported = Object.keys(ENV_VAR_MAP).join(", ");
    throw new Error(
      `Unknown LLM provider '${provider}'. Supported providers: ${supported}.`
    );
  }

  const apiKey = process.env[envVar];
  if (!apiKey || apiKey.trim() === "") {
    throw new Error(
      `${envVar} environment variable not found. Set it with: export ${envVar}=<your-key>`
    );
  }

  return apiKey.trim();
}

export function validateApiKey(provider: string): void {
  const normalized = provider.trim().toLowerCase() as LLMProvider;
  const envVar = ENV_VAR_MAP[normalized];
  if (!envVar) return;

  const apiKey = process.env[envVar];
  if (!apiKey) return;

  const expectedPrefix = KEY_PREFIX_MAP[normalized];
  if (expectedPrefix && !apiKey.startsWith(expectedPrefix)) {
    console.warn(
      `Warning: ${provider} API key does not start with '${expectedPrefix}' - this may be incorrect`
    );
  }

  const placeholders = ["YOUR_API_KEY", "xxx", "test", "demo", "placeholder"];
  const lowerKey = apiKey.toLowerCase();
  for (const placeholder of placeholders) {
    if (lowerKey.includes(placeholder)) {
      console.warn(
        `Warning: ${provider} API key appears to contain a placeholder ('${placeholder}')`
      );
      break;
    }
  }

  if (apiKey.length < 20) {
    console.warn(
      `Warning: ${provider} API key seems too short (${apiKey.length} chars) - this may be incorrect`
    );
  }
}

export function getModel(config: { provider: string; model: string; apiKey?: string }): LanguageModel {
  try {
    const provider = config.provider as LLMProvider;
    const apiKey = config.apiKey || getApiKey(provider);
    
    switch (provider) {
      case "openai": return createOpenAI({ apiKey })(config.model);
      case "anthropic": return createAnthropic({ apiKey })(config.model);
      case "google": return createGoogleGenerativeAI({ apiKey })(config.model);
      default: throw new Error(`Unsupported provider: ${config.provider}`);
    }
  } catch (err: any) {
    throw err;
  }
}

export function isLLMAvailable(provider: LLMProvider): boolean {
  const envVar = ENV_VAR_MAP[provider];
  return !!process.env[envVar];
}

export function getAvailableProviders(): LLMProvider[] {
  return (Object.keys(ENV_VAR_MAP) as LLMProvider[]).filter((provider) =>
    isLLMAvailable(provider)
  );
}

// --- Prompt Templates ---

export const PROMPTS = {
  diary: `You are analyzing a coding agent session to extract structured insights.

SESSION METADATA:
- Path: {sessionPath}
- Agent: {agent}
- Workspace: {workspace}

<session_content>
{content}
</session_content>

INSTRUCTIONS:
Extract the following from the session content above. Be SPECIFIC and ACTIONABLE.
Avoid generic statements like "wrote code" or "fixed bug".
Include specific:
- File names and paths
- Function/class/component names
- Error messages and stack traces
- Commands run
- Tools used

If the session lacks information for a field, provide an empty array.

Respond with JSON matching this schema:
{
  "status": "success" | "failure" | "mixed",
  "accomplishments": string[],  // Specific completed tasks with file/function names
  "decisions": string[],        // Design choices with rationale
  "challenges": string[],       // Problems encountered, errors, blockers
  "preferences": string[],      // User style revelations
  "keyLearnings": string[],     // Reusable insights
  "tags": string[],             // Discovery keywords
  "searchAnchors": string[]     // Search phrases for future retrieval
}`,

  reflector: `You are analyzing a coding session diary to extract reusable lessons for a playbook.

<existing_playbook>
{existingBullets}
</existing_playbook>

<session_diary>
{diary}
</session_diary>

<cass_history>
{cassHistory}
</cass_history>

{iterationNote}

INSTRUCTIONS:
Extract playbook deltas (changes) from this session. Each delta should be:
- SPECIFIC: Bad: "Write tests". Good: "For React hooks, test effects separately with renderHook"
- ACTIONABLE: Include concrete examples, file patterns, command flags
- REUSABLE: Would help a DIFFERENT agent on a similar problem

Delta types:
- add: New insight not covered by existing bullets
- helpful: Existing bullet proved useful (reference by ID)
- harmful: Existing bullet caused problems (reference by ID, explain why)
- replace: Existing bullet needs updated wording
- deprecate: Existing bullet is outdated

Maximum 20 deltas per reflection. Focus on quality over quantity.`,

  validator: `You are a scientific validator checking if a proposed rule is supported by historical evidence.

<proposed_rule>
{proposedRule}
</proposed_rule>

<historical_evidence>
{evidence}
</historical_evidence>

INSTRUCTIONS:
Analyze whether the evidence supports, contradicts, or is neutral toward the proposed rule.

Consider:
1. How many sessions show success when following this pattern?
2. How many sessions show failure when following this pattern?
3. Are there edge cases or conditions where the rule doesn't apply?
4. Is the rule too broad or too specific?

Respond with:
{
  "verdict": "ACCEPT" | "REJECT" | "REFINE",
  "confidence": number,  // 0.0-1.0
  "reason": string,
  "suggestedRefinement": string | null,  // Suggested improvement if partially valid
  "evidence": { "supporting": string[], "contradicting": string[] }
}`,

  context: `You are preparing a context briefing for a coding task.

TASK DESCRIPTION:
{task}

<playbook_rules>
{bullets}
</playbook_rules>

<session_history>
{history}
</session_history>

<deprecated_patterns>
{deprecatedPatterns}
</deprecated_patterns>

INSTRUCTIONS:
Create a concise briefing that:
1. Summarizes the most relevant rules for this task
2. Highlights any pitfalls or anti-patterns to avoid
3. Suggests relevant cass searches for deeper context
4. Notes any deprecated patterns that might come up

Keep the briefing actionable and under 500 words.`,

  audit: `You are auditing a coding session to check if established rules were followed.

<session_content>
{sessionContent}
</session_content>

<rules_to_check>
{rulesToCheck}
</rules_to_check>

INSTRUCTIONS:
For each rule, determine if the session:
- FOLLOWED the rule (with evidence)
- VIOLATED the rule (with evidence)
- Rule was NOT APPLICABLE to this session

Respond with:
{
  "results": [
    {
      "ruleId": string,
      "status": "followed" | "violated" | "not_applicable",
      "evidence": string
    }
  ],
  "summary": string
}`,
} as const;

export function fillPrompt(
  template: string,
  values: Record<string, string>
): string {
  let result = template;
  for (const [key, value] of Object.entries(values)) {
    result = result.replace(new RegExp(`\\{${key}\\}`, "g"), value);
  }
  return result;
}

export function truncateForPrompt(content: string, maxChars = 50000): string {
  if (content.length <= maxChars) return content;

  const keepChars = Math.floor((maxChars - 100) / 2);
  const beginning = content.slice(0, keepChars);
  const ending = content.slice(-keepChars);

  return `${beginning}\n\n[... ${content.length - maxChars} characters truncated ...]\n\n${ending}`;
}

// --- Resilience Wrapper ---

export const LLM_RETRY_CONFIG = {
  maxRetries: 3,
  baseDelayMs: 1000,
  maxDelayMs: 30000,
  retryableErrors: [
    "rate_limit_exceeded",
    "server_error",
    "timeout",
    "overloaded",
    "ETIMEDOUT",
    "ECONNRESET",
    "429",
    "500",
    "503"
  ]
};

export async function llmWithRetry<T>(
  operation: () => Promise<T>,
  operationName: string
): Promise<T> {
  let attempt = 0;
  while (true) {
    try {
      return await operation();
    } catch (err: any) {
      attempt++;
      const isRetryable = LLM_RETRY_CONFIG.retryableErrors.some(e => 
        err.message?.toLowerCase().includes(e) || err.code?.toString().includes(e) || err.statusCode?.toString().includes(e)
      );
      
      if (!isRetryable || attempt > LLM_RETRY_CONFIG.maxRetries) {
        throw err;
      }
      
      const delay = Math.min(
        LLM_RETRY_CONFIG.baseDelayMs * Math.pow(2, attempt), 
        LLM_RETRY_CONFIG.maxDelayMs
      );
      
      // Using console directly as log utility imports might cycle (simplified)
      console.warn(`[LLM] ${operationName} failed (attempt ${attempt}): ${err.message}. Retrying in ${delay}ms...`);
      await new Promise(resolve => setTimeout(resolve, delay));
    }
  }
}

/**
 * Safe wrapper for generateObject that retries with enhanced prompts on validation failure.
 *
 * Unlike llmWithRetry (which handles network/rate limit errors), this specifically handles
 * cases where the LLM produces malformed JSON or misses required schema fields.
 *
 * On failure, it modifies the prompt to:
 * - Emphasize JSON format requirements
 * - Slightly increase temperature to avoid repeating the same error
 * - Add explicit schema validation notice
 *
 * @param schema - Zod schema for validation
 * @param prompt - Original prompt
 * @param config - LLM configuration
 * @param maxAttempts - Maximum retry attempts (default: 2)
 * @returns Validated result matching schema
 *
 * @example
 * const diary = await generateObjectSafe(DiaryEntrySchema, prompt, config);
 */
export async function generateObjectSafe<T>(
  schema: z.ZodSchema<T>,
  prompt: string,
  config: { provider: string; model: string; apiKey?: string },
  maxAttempts: number = 2
): Promise<T> {
  const model = getModel(config);
  let lastError: Error | null = null;

  for (let attempt = 1; attempt <= maxAttempts; attempt++) {
    try {
      // On retry, enhance the prompt with validation emphasis
      const enhancedPrompt = attempt > 1
        ? `[PREVIOUS ATTEMPT FAILED - OUTPUT MUST BE VALID JSON]\n\n${prompt}\n\nCRITICAL: Your response MUST be valid JSON matching the provided schema exactly. Ensure all required fields are present.`
        : prompt;

      // Slightly increase temperature on retry to avoid same error
      const temperature = attempt > 1 ? 0.35 : 0.3;

      const { object } = await generateObject({
        model,
        schema,
        prompt: enhancedPrompt,
        temperature
      });

      // Double-check validation (SDK should already validate, but be safe)
      const validated = schema.parse(object);
      return validated;
    } catch (err: any) {
      lastError = err;
      if (attempt < maxAttempts) {
        console.warn(`[LLM] generateObjectSafe attempt ${attempt} failed: ${err.message}. Retrying...`);
      }
    }
  }

  throw lastError ?? new Error("generateObjectSafe failed after all attempts");
}

// --- Operations ---

export async function extractDiary<T>(
  schema: z.ZodSchema<T>,
  sessionContent: string,
  metadata: { sessionPath: string; agent: string; workspace?: string },
  config: Config
): Promise<T> {
  const llmConfig: LLMConfig = {
    provider: (config.llm?.provider ?? config.provider) as LLMProvider,
    model: config.llm?.model ?? config.model,
    apiKey: config.apiKey
  };

  const model = getModel(llmConfig);
  
  const truncatedContent = truncateForPrompt(sessionContent, 50000);

  const prompt = fillPrompt(PROMPTS.diary, {
    sessionPath: metadata.sessionPath,
    agent: metadata.agent,
    workspace: metadata.workspace || "unknown",
    content: truncatedContent
  });

  return llmWithRetry(async () => {
    const { object } = await generateObject({
      model,
      schema,
      prompt,
      temperature: 0.3,
    });
    return object;
  }, "extractDiary");
}

export async function runReflector<T>(
  schema: z.ZodSchema<T>,
  diary: DiaryEntry,
  existingBullets: string,
  cassHistory: string,
  iteration: number,
  config: Config
): Promise<T> {
  const llmConfig: LLMConfig = {
    provider: (config.llm?.provider ?? config.provider) as LLMProvider,
    model: config.llm?.model ?? config.model,
    apiKey: config.apiKey
  };

  const model = getModel(llmConfig);

  const diaryText = `
Status: ${diary.status}
Accomplishments: ${diary.accomplishments.join('\n- ')}
Decisions: ${diary.decisions.join('\n- ')}
Challenges: ${diary.challenges.join('\n- ')}
Preferences: ${diary.preferences.join('\n- ')}
Key Learnings: ${diary.keyLearnings.join('\n- ')}
`.trim();

  const iterationNote = iteration > 0
    ? `This is iteration ${iteration + 1}. Focus on insights you may have missed in previous passes.`
    : "";

  // Truncate large inputs to prevent context overflow
  const safeExistingBullets = truncateForPrompt(existingBullets, 20000);
  const safeCassHistory = truncateForPrompt(cassHistory, 20000);

  const prompt = fillPrompt(PROMPTS.reflector, {
    existingBullets: safeExistingBullets,
    diary: diaryText,
    cassHistory: safeCassHistory,
    iterationNote,
  });

  return llmWithRetry(async () => {
    const { object } = await generateObject({
      model,
      schema,
      prompt,
      temperature: 0.5,
    });
    return object;
  }, "runReflector");
}

export interface ValidatorResult {
  valid: boolean;
  verdict: 'ACCEPT' | 'REJECT' | 'REFINE';
  confidence: number;
  reason: string;
  evidence: Array<{ sessionPath: string; snippet: string; supports: boolean }>;
  suggestedRefinement?: string;
}

const ValidatorOutputSchema = z.object({
  verdict: z.enum(['ACCEPT', 'REJECT', 'REFINE']),
  confidence: z.number().min(0).max(1),
  reason: z.string(),
  evidence: z.object({
    supporting: z.array(z.string()).default([]),
    contradicting: z.array(z.string()).default([])
  }),
  suggestedRefinement: z.string().optional().nullable()
});

export async function runValidator(
  proposedRule: string,
  formattedEvidence: string,
  config: Config
): Promise<ValidatorResult> {
  const llmConfig: LLMConfig = {
    provider: (config.llm?.provider ?? config.provider) as LLMProvider,
    model: config.llm?.model ?? config.model,
    apiKey: config.apiKey
  };

  const model = getModel(llmConfig);

  const safeEvidence = truncateForPrompt(formattedEvidence, 30000);

  const prompt = fillPrompt(PROMPTS.validator, {
    proposedRule,
    evidence: safeEvidence
  });

  return llmWithRetry(async () => {
    const { object } = await generateObject({
      model,
      schema: ValidatorOutputSchema,
      prompt,
      temperature: 0.2,
    });

    const mappedEvidence = [
      ...object.evidence.supporting.map(s => ({ sessionPath: "unknown", snippet: s, supports: true })),
      ...object.evidence.contradicting.map(s => ({ sessionPath: "unknown", snippet: s, supports: false }))
    ];

    return {
      valid: object.verdict === 'ACCEPT',
      verdict: object.verdict,
      confidence: object.confidence,
      reason: object.reason,
      evidence: mappedEvidence,
      suggestedRefinement: object.suggestedRefinement || undefined
    };
  }, "runValidator");
}

export async function generateContext(
  task: string,
  bullets: string,
  history: string,
  deprecatedPatterns: string,
  config: Config
): Promise<string> {
  const llmConfig: LLMConfig = {
    provider: (config.llm?.provider ?? config.provider) as LLMProvider,
    model: config.llm?.model ?? config.model,
    apiKey: config.apiKey
  };

  const model = getModel(llmConfig);

  const prompt = fillPrompt(PROMPTS.context, {
    task: truncateForPrompt(task, 5000),
    bullets: truncateForPrompt(bullets, 20000),
    history: truncateForPrompt(history, 20000),
    deprecatedPatterns: truncateForPrompt(deprecatedPatterns, 5000)
  });

  return llmWithRetry(async () => {
    const { object } = await generateObject({
      model,
      schema: z.object({ briefing: z.string() }), // Using structured object to force format
      prompt,
      temperature: 0.3,
    });
    return object.briefing;
  }, "generateContext");
}

export async function generateSearchQueries(
  task: string,
  config: Config
): Promise<string[]> {
  const llmConfig: LLMConfig = {
    provider: (config.llm?.provider ?? config.provider) as LLMProvider,
    model: config.llm?.model ?? config.model,
    apiKey: config.apiKey
  };

  const model = getModel(llmConfig);

  const prompt = `Given this task: ${truncateForPrompt(task, 5000)}

Generate 3-5 diverse search queries to find relevant information:
- Similar problems encountered before
- Related frameworks or tools
- Relevant patterns or best practices
- Error messages or debugging approaches

Make queries specific enough to be useful but broad enough to match variations.`;

  return llmWithRetry(async () => {
    const { object } = await generateObject({
      model,
      schema: z.object({ queries: z.array(z.string()).max(5) }),
      prompt,
      temperature: 0.5,
    });
    return object.queries;
  }, "generateSearchQueries");
}

// --- Multi-Provider Fallback ---

/**
 * Preferred fallback order when primary provider fails.
 * Rationale:
 * - Anthropic: Strong reasoning, reliable structured output
 * - OpenAI: Fast, widely available
 * - Google: Additional fallback option
 */
const FALLBACK_ORDER: LLMProvider[] = ["anthropic", "openai", "google"];

/**
 * Default model for each provider when used as fallback.
 * These are reliable models with good structured output support.
 */
const FALLBACK_MODELS: Record<LLMProvider, string> = {
  anthropic: "claude-sonnet-4-20250514",
  openai: "gpt-4o-mini",
  google: "gemini-2.0-flash",
};

/**
 * Multi-provider fallback for LLM operations.
 *
 * Protects against provider-specific outages by trying multiple providers
 * in sequence until one succeeds. Use when uptime matters more than
 * specific provider characteristics.
 *
 * @param schema - Zod schema for structured output validation
 * @param prompt - The prompt to send to the LLM
 * @param config - Configuration with primary provider and fallbackEnabled flag
 * @returns Validated object matching the schema
 * @throws Error if all providers fail (includes all error messages)
 *
 * @example
 * const result = await llmWithFallback(
 *   z.object({ summary: z.string() }),
 *   "Summarize this text...",
 *   config
 * );
 */
export async function llmWithFallback<T>(
  schema: z.ZodSchema<T>,
  prompt: string,
  config: Config
): Promise<T> {
  // Get primary provider from config
  const primaryProvider = (config.llm?.provider ?? config.provider) as LLMProvider;
  const primaryModel = config.llm?.model ?? config.model;

  // Build provider order: primary first, then available fallbacks
  const availableProviders = getAvailableProviders();
  const providerOrder: Array<{ provider: LLMProvider; model: string }> = [];

  // Add primary provider if available
  if (availableProviders.includes(primaryProvider)) {
    providerOrder.push({ provider: primaryProvider, model: primaryModel });
  }

  // Add fallback providers (skip primary to avoid duplicates)
  for (const fallback of FALLBACK_ORDER) {
    if (fallback !== primaryProvider && availableProviders.includes(fallback)) {
      providerOrder.push({ provider: fallback, model: FALLBACK_MODELS[fallback] });
    }
  }

  if (providerOrder.length === 0) {
    throw new Error(
      "No LLM providers available. Set one of: OPENAI_API_KEY, ANTHROPIC_API_KEY, or GOOGLE_GENERATIVE_AI_API_KEY"
    );
  }

  // Collect errors for combined error message
  const errors: Array<{ provider: string; error: string }> = [];

  for (const { provider, model } of providerOrder) {
    try {
      const llmModel = getModel({ provider, model });

      const { object } = await generateObject({
        model: llmModel,
        schema,
        prompt,
        temperature: 0.3,
      });

      // Success - return the result
      return object;
    } catch (err: any) {
      const errorMsg = err.message || String(err);
      errors.push({ provider, error: errorMsg });

      // Log fallback attempt (but continue trying)
      console.warn(`[LLM] ${provider} failed: ${errorMsg}. Trying next provider...`);
    }
  }

  // All providers failed - throw combined error
  const errorSummary = errors
    .map(e => `${e.provider}: ${e.error}`)
    .join("\n  ");

  throw new Error(`All LLM providers failed:\n  ${errorSummary}`);
}